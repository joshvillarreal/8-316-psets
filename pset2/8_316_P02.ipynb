{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c4b6fea3",
      "metadata": {
        "tags": [
          "learner",
          "md",
          "learner_chopped"
        ],
        "id": "c4b6fea3"
      },
      "source": [
        "<hr style=\"height: 1px;\">\n",
        "<i>This notebook was authored by the 8.S50x Course Team, Copyright 2022 MIT All Rights Reserved.</i>\n",
        "<hr style=\"height: 1px;\">\n",
        "<br>\n",
        "\n",
        "<h1>PSet 2: Matched Filtering Part: Time Domain and Frequency Domain</h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99b5fd44",
      "metadata": {
        "tags": [
          "learner",
          "md",
          "learner_chopped"
        ],
        "id": "99b5fd44"
      },
      "source": [
        "<a name='section_6_0'></a>\n",
        "<hr style=\"height: 1px;\">\n",
        "\n",
        "\n",
        "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">P2.0 Overview</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f64e91e",
      "metadata": {
        "tags": [
          "md",
          "learner",
          "learner_chopped"
        ],
        "id": "5f64e91e"
      },
      "source": [
        "<h3>Navigation</h3>\n",
        "\n",
        "<table style=\"width:100%\">\n",
        "    <tr>\n",
        "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_6_1\">P2.1 What is Matched Filtering?</a>\n",
        "        </td>\n",
        "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#problems_6_1\">P2.1 Problems</a>\n",
        "        </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_6_2\">P2.2 Fitting in the Time Domain: Part I</a>\n",
        "        </td>\n",
        "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#problems_6_2\">P2.2 Problems</a>\n",
        "        </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_6_3\">P2.3 Fitting in the Time Domain: Part II</a>\n",
        "        </td>\n",
        "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#problems_6_3\">P2.3 Problems</a>\n",
        "        </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_6_4\">P2.4 Sweeping the Time Window</a>\n",
        "        </td>\n",
        "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#problems_6_4\">P2.4 Problems</a></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_7_1\">P2.5 Introduction to Fitting in the Frequency Domain</a>\n",
        "        </td>\n",
        "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\">no problems</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_7_2\">P2.6 Analysis of Noisy Car Horn Data</a>\n",
        "        </td>\n",
        "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#problems_7_2\">P2.6 Problems</a></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_7_3\">P2.7 Calculating a Better Chi-square for the LIGO Model</a>\n",
        "        </td>\n",
        "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#problems_7_3\">P2.7 Problems</a></td>\n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8285af82",
      "metadata": {
        "tags": [
          "learner",
          "md"
        ],
        "id": "8285af82"
      },
      "source": [
        "<h3>Learning Objectives</h3>\n",
        "\n",
        "In this Pset we will define matched filtering and look at an example in the time domain."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8ff107e",
      "metadata": {
        "tags": [
          "learner",
          "md"
        ],
        "id": "a8ff107e"
      },
      "source": [
        "<h3>Importing Libraries</h3>\n",
        "\n",
        "Before beginning, run the cell below to import the relevant libraries for this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6cc1452",
      "metadata": {
        "tags": [
          "learner",
          "py",
          "learner_chopped"
        ],
        "id": "a6cc1452"
      },
      "outputs": [],
      "source": [
        "#>>>RUN: P2.0-runcell00\n",
        "\n",
        "!pip install lmfit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "036dd61b",
      "metadata": {
        "tags": [
          "learner",
          "py",
          "learner_chopped"
        ],
        "id": "036dd61b"
      },
      "outputs": [],
      "source": [
        "#>>>RUN: P2.0-runcell01\n",
        "\n",
        "import numpy as np                 #https://numpy.org/doc/stable/\n",
        "import matplotlib.pyplot as plt    #https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.html\n",
        "from mpl_toolkits import mplot3d   #https://matplotlib.org/2.0.2/mpl_toolkits/mplot3d/tutorial.html\n",
        "\n",
        "import scipy.stats as stats        #https://docs.scipy.org/doc/scipy/reference/stats.html\n",
        "from scipy.stats import chisquare  #https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chisquare.html\n",
        "\n",
        "import lmfit\n",
        "from lmfit import Model,Parameters #https://lmfit.github.io/lmfit-py/parameters.html\n",
        "                                     #https://lmfit.github.io/lmfit-py/model.html#lmfit.model.Model\n",
        "\n",
        "from scipy.io.wavfile import write   #https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.wavfile.write.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "213cdb84",
      "metadata": {
        "tags": [
          "learner",
          "md"
        ],
        "id": "213cdb84"
      },
      "source": [
        "<h3>Setting Default Figure Parameters</h3>\n",
        "\n",
        "The following code cell sets default values for figure parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6631215",
      "metadata": {
        "tags": [
          "learner",
          "py",
          "learner_chopped"
        ],
        "id": "b6631215"
      },
      "outputs": [],
      "source": [
        "#>>>RUN: P2.0-runcell02\n",
        "\n",
        "#set plot resolution\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "#set default figure parameters\n",
        "plt.rcParams['figure.figsize'] = (9,6)\n",
        "\n",
        "medium_size = 12\n",
        "large_size = 15\n",
        "\n",
        "plt.rc('font', size=medium_size)          # default text sizes\n",
        "plt.rc('xtick', labelsize=medium_size)    # xtick labels\n",
        "plt.rc('ytick', labelsize=medium_size)    # ytick labels\n",
        "plt.rc('legend', fontsize=medium_size)    # legend\n",
        "plt.rc('axes', titlesize=large_size)      # axes title\n",
        "plt.rc('axes', labelsize=large_size)      # x and y labels\n",
        "plt.rc('figure', titlesize=large_size)    # figure title"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a63bb28a",
      "metadata": {
        "tags": [
          "learner",
          "md",
          "learner_chopped"
        ],
        "id": "a63bb28a"
      },
      "source": [
        "<a name='section_6_1'></a>\n",
        "<hr style=\"height: 1px;\">\n",
        "\n",
        "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">P2.1 What is Matched Filtering?</h2>    \n",
        "\n",
        "| [Top](#section_6_0) | [Previous Section](#section_6_0) | [Problems](#problems_6_1) | [Next Section](#section_6_2) |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37a135fc",
      "metadata": {
        "tags": [
          "learner",
          "md"
        ],
        "id": "37a135fc"
      },
      "source": [
        "<h3>Overview</h3>\n",
        "\n",
        "The purpose of matched filtering is to scan big data sets looking for some kind of signal. LIGO does this to look for gravitational waves in their strain data. Matched filtering is also done in many other fields.\n",
        "\n",
        "The output of this process is usually a plot of the signal to noise ratio (SNR) for the data. If you're looking for point sources in astrophysical telescope data, for example, the plot is an image  with right ascension and declination as the axes and SNR shown as the z axis (contours or simply brightness). The LIGO analysis uses a 2D plot with time on the x axis and SNR on the y axis.\n",
        "\n",
        "\n",
        "Signals look like large spikes in the SNR."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3a5a45f",
      "metadata": {
        "tags": [
          "learner",
          "md"
        ],
        "id": "f3a5a45f"
      },
      "source": [
        "To make this exercise useful to you in the LIGO project, we'll make a model signal that resembles a black hole merger. Run the code below to generate and plot an example of the waveform. (This is nearly the same function as was used in Guided Problem Set 3).\n",
        "\n",
        "Note, in particular, that the input parameter `TIME_TRUE` corresponds to the time at which the signal function has its maximum value. This will be important to remember in the analysis that follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf85f302",
      "metadata": {
        "tags": [
          "learner",
          "py",
          "learner_chopped"
        ],
        "id": "cf85f302"
      },
      "outputs": [],
      "source": [
        "#>>>RUN: P2.1-runcell01\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(0x98a09fe)\n",
        "\n",
        "def complicated_model_fn(x, time, lambda_plus, lambda_minus, max_amp, omega_0, omega_max, omega_sigma):\n",
        "    omega = (omega_max - omega_0) * (np.exp(-np.minimum(x - time, 0)**2 / omega_sigma)) + omega_0\n",
        "    lambdas = np.array([lambda_plus if xvalue > time else lambda_minus for xvalue in x])\n",
        "    amplitude = max_amp * np.exp(-abs(x - time) / lambdas)\n",
        "    return amplitude * np.cos(omega * (x-time))\n",
        "\n",
        "LAMBDA_PLUS_TRUE = 1.0\n",
        "LAMBDA_MINUS_TRUE = 4\n",
        "MAX_AMP_TRUE = 1.2\n",
        "OMEGA_0_TRUE = 3.0\n",
        "OMEGA_MAX_TRUE = 6.0\n",
        "OMEGA_SIGMA_TRUE = 4.0\n",
        "TIME_TRUE = 50.0\n",
        "\n",
        "xi = np.linspace(TIME_TRUE-15, TIME_TRUE+5, 200)\n",
        "yi_true = complicated_model_fn(xi, TIME_TRUE, LAMBDA_PLUS_TRUE, LAMBDA_MINUS_TRUE, MAX_AMP_TRUE,\n",
        "                               OMEGA_0_TRUE, OMEGA_MAX_TRUE, OMEGA_SIGMA_TRUE)\n",
        "\n",
        "plt.plot(xi, yi_true)\n",
        "plt.xlabel(\"Time (s)\")\n",
        "plt.ylabel(\"Strain\");"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbe8bd05",
      "metadata": {
        "tags": [
          "learner",
          "md"
        ],
        "id": "dbe8bd05"
      },
      "source": [
        "Now, let's make some fake data using this waveform as a merger signal and superimposing simulated \"noise\" as ten sinusoids of varying frequency, phase, and amplitude added together. Make sure you take the time to read the code and understand exactly what it does."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8970ff43",
      "metadata": {
        "tags": [
          "learner",
          "py",
          "learner_chopped"
        ],
        "id": "8970ff43"
      },
      "outputs": [],
      "source": [
        "#>>>RUN: P2.1-runcell02\n",
        "\n",
        "np.random.seed(0x98a09fe)\n",
        "#np.random.seed(908)\n",
        "\n",
        "NUMBER_SINES_TO_ADD = 10\n",
        "\n",
        "noise_frequencies = 0.5 + 7 * np.random.random(NUMBER_SINES_TO_ADD)\n",
        "noise_phases = 2 * np.pi * np.random.random(NUMBER_SINES_TO_ADD)\n",
        "noise_amplitudes = 2 * MAX_AMP_TRUE / NUMBER_SINES_TO_ADD * np.random.random(NUMBER_SINES_TO_ADD)\n",
        "    # The above line sets noise amplitudes so that the sum of all the noise amplitudes is on average\n",
        "    # equal to the maximum amplitude of the signal.\n",
        "\n",
        "sample_spacing = 0.1\n",
        "xi = np.arange(-128, 128, sample_spacing)#times\n",
        "yi = np.zeros_like(xi)#data\n",
        "\n",
        "#Adding Noise\n",
        "for freq, phase, amplitude in zip(noise_frequencies, noise_phases, noise_amplitudes):\n",
        "    yi += amplitude * np.sin(phase + freq * xi)\n",
        "   \n",
        "#Adding Data\n",
        "signal = complicated_model_fn(xi, TIME_TRUE, LAMBDA_PLUS_TRUE, LAMBDA_MINUS_TRUE, MAX_AMP_TRUE,\n",
        "                               OMEGA_0_TRUE, OMEGA_MAX_TRUE, OMEGA_SIGMA_TRUE)\n",
        "\n",
        "yi+=signal\n",
        "\n",
        "plt.figure(figsize=(16, 5))\n",
        "plt.plot(xi, yi)\n",
        "plt.title(\"Signal plus noise\")\n",
        "plt.xlabel(\"Time (s)\")\n",
        "plt.ylabel(\"Strain\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(16, 5))\n",
        "plt.plot(xi, yi)\n",
        "plt.plot(xi, signal)\n",
        "plt.title(\"Signal plus noise\")\n",
        "plt.xlabel(\"Time (s)\")\n",
        "plt.ylabel(\"Strain\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(xi, yi)\n",
        "plt.plot(xi, signal)\n",
        "plt.title(\"Signal plus noise\")\n",
        "plt.xlim(35,55)\n",
        "plt.xlabel(\"Time (s)\")\n",
        "plt.ylabel(\"Strain\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bb48cf8",
      "metadata": {
        "tags": [
          "learner",
          "md"
        ],
        "id": "2bb48cf8"
      },
      "source": [
        "When you blow up the region around t=TRUE_TIME and overlay the signal waveform, the correspondence is clear, but could you figure this out given only the noisy data in the first plot? **Our goal is to accomplish the seemingly impossible task of finding the signal in this data.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "595ea9ff",
      "metadata": {
        "tags": [
          "learner",
          "md",
          "learner_chopped"
        ],
        "id": "595ea9ff"
      },
      "source": [
        "<a name='problems_6_1'></a>     \n",
        "\n",
        "| [Top](#section_6_0) | [Restart Section](#section_6_1) | [Next Section](#section_6_2) |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84a4d4d6",
      "metadata": {
        "tags": [
          "learner",
          "md",
          "learner_chopped"
        ],
        "id": "84a4d4d6"
      },
      "source": [
        "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 2.1.1</span>\n",
        "\n",
        "In the next four problems, we will generate some noise and create a SNR (signal to noise ratio) plot in order to identify the time at which the signal exists. Since we already know the signal and the noise separately, we can implement a naive approach to finding the signal time. We will calculate the SNR and then simply take the time at which its maximum occurs as the time for the signal event. Your goal is to explore how well this crude method works.\n",
        "\n",
        "First, generate some noise composed of 1,000 sines (100 times as many as above!) with frequencies randomly taken from a normal distribution with mean at $\\mu=0.8$ and standard deviation of $\\sigma =5$, phases taken from a random uniform distribution ranging from 0 to $2\\pi$, and amplitudes set so that the sum of all the noise amplitudes is on average equal to the maximum amplitude of the signal.\n",
        "\n",
        "In a previous assignment, we did something similar with only 10 sines, but we sampled from slightly different distributions. You can refer back to that previous example, if necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d25fc706",
      "metadata": {
        "tags": [
          "draft",
          "py",
          "learner_chopped"
        ],
        "id": "d25fc706"
      },
      "outputs": [],
      "source": [
        "#>>>PROBLEM: P2.1.1\n",
        "# Use this cell for drafting your solution (if desired),\n",
        "# then enter your solution in the interactive problem online to be graded.\n",
        "\n",
        "MAX_AMP_TRUE = 1.2\n",
        "SAMPLE_SPACING = 0.1\n",
        "NUMBER_SINES_TO_ADD = 1000\n",
        "\n",
        "xi = np.arange(0, 128, SAMPLE_SPACING)#times\n",
        "\n",
        "def generate_noise(xi):\n",
        "  np.random.seed(908)\n",
        "  yi_noise = np.zeros_like(xi)\n",
        "\n",
        "  noise_frequencies = 0 #YOUR CODE HERE\n",
        "  noise_phases = 0 #YOUR CODE HERE\n",
        "  noise_amplitudes = 0 #YOUR CODE HERE\n",
        "\n",
        "  #Adding Noise\n",
        "  for freq, phase, amplitude in zip(noise_frequencies, noise_phases, noise_amplitudes):\n",
        "      yi_noise += amplitude * np.sin( phase + freq * xi)\n",
        "\n",
        "  return yi_noise\n",
        "\n",
        "plt.figure(figsize=(16, 5))\n",
        "plt.xlabel(\"Time (s)\")\n",
        "plt.ylabel(\"Strain\")\n",
        "plt.plot(xi, generate_noise(xi))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16c20672",
      "metadata": {
        "tags": [
          "learner",
          "md",
          "learner_chopped"
        ],
        "id": "16c20672"
      },
      "source": [
        "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 2.1.2</span>\n",
        "\n",
        "Now, we want to inject a signal waveform on top of the noise signal we just generated. Then, we will use a very simple approach to try to \"find\" that signal, namely looking for the location in the total amplitude which has the maximum value. Recall that the maximum amplitude of the merger signal is the parameter `TRUE_TIME`. So,  we can determine how well we \"found\" the injected signal by checking if the time we found in the total data is consistent with the `TRUE_TIME` of the injected waveform. \n",
        "\n",
        "To begin, create a set of 50 signals of the form shown earlier. Except for the `TRUE_TIME`, each waveform will have identical parameters as shown in the code below. The `TRUE_TIME` parameters of the injected signals should range over every whole second in the range [50, 100) (i.e., you should generate signals with `TRUE_TIME`=50, `TRUE_TIME`=51, ... `TRUE_TIME`=99).\n",
        "\n",
        "For each merger signal, inject it on top of the noise generated earlier and try to find the time at which the injection happens by looking for the maximum amplitude in the combined data. Lastly, make a plot of the true (injected) time, vs the time at which you found the maximum. Notice the `scale` parameter in the function `get_max_times`. This option can be used to rescale the size of the merger signal before it gets injected (in this case, `scale=1.0`, so we used the unmodified merger waveform). \n",
        "\n",
        "HINT: Take a look at the `np.argmax()` function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "302f25a0",
      "metadata": {
        "tags": [
          "draft",
          "py",
          "learner_chopped"
        ],
        "id": "302f25a0"
      },
      "outputs": [],
      "source": [
        "#>>>PROBLEM: P2.1.2\n",
        "# Use this cell for drafting your solution (if desired),\n",
        "# then enter your solution in the interactive problem online to be graded.\n",
        "\n",
        "LAMBDA_PLUS_TRUE = 1.0\n",
        "LAMBDA_MINUS_TRUE = 4\n",
        "MAX_AMP_TRUE = 1.2\n",
        "OMEGA_0_TRUE = 3.0\n",
        "OMEGA_MAX_TRUE = 6.0\n",
        "OMEGA_SIGMA_TRUE = 4.0\n",
        "\n",
        "def complicated_model_fn(x, time, lambda_plus, lambda_minus, max_amp, omega_0, omega_max, omega_sigma):\n",
        "    omega = (omega_max - omega_0) * (np.exp(-np.minimum(x - time, 0)**2 / omega_sigma)) + omega_0\n",
        "    lambdas = np.array([lambda_plus if xvalue > time else lambda_minus for xvalue in x])\n",
        "    amplitude = max_amp * np.exp(-abs(x - time) / lambdas)\n",
        "    return amplitude * np.cos(omega * (x-time))\n",
        "\n",
        "def get_max_times(xi, yi_noise, true_times,scale=1.0,iCheck=False):\n",
        "    time_of_maximums = []\n",
        "\n",
        "    for t in true_times:\n",
        "\n",
        "        yi_signal = #YOUR CODE HERE\n",
        "        yi_test_noise = #YOUR CODE HERE\n",
        "        SNR = #YOUR CODE HERE\n",
        "        \n",
        "        time_of_maximums.append(xi[np.argmax(SNR)])\n",
        "        \n",
        "        if int(t) == 75 and iCheck:\n",
        "            plt.xlabel(\"Time (s)\")\n",
        "            plt.ylabel(\"Strain\")\n",
        "            plt.plot(xi,yi_test_noise)\n",
        "            plt.plot(xi,yi_signal)\n",
        "            plt.show()\n",
        "        \n",
        "    return time_of_maximums\n",
        "\n",
        "true_times = np.linspace(50, 100, 50)\n",
        "xi = np.arange(0, 128, SAMPLE_SPACING)\n",
        "yi_noise = generate_noise(xi)\n",
        "\n",
        "plt.plot(true_times, get_max_times(xi, yi_noise, true_times, iCheck=True), label = 'naive model')\n",
        "plt.xlabel('True Times (s)')\n",
        "plt.ylabel('Found Times (s)')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "701bf981",
      "metadata": {
        "tags": [
          "learner",
          "md",
          "learner_chopped"
        ],
        "id": "701bf981"
      },
      "source": [
        "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 2.1.3</span>\n",
        "\n",
        "The code for the previous problem plotted the found time versus the true time (true time on the x-axis, estimated time for y) and that result looked quite good. Let's check this comparison more carefully. \n",
        "\n",
        "First, modify the code below to add to the plot what a perfect algorithm would look like, namely the line y=x. You might want to give this line a different color so you can distinguish it from the data result, and plot it *after* the other line to put it on top. \n",
        "\n",
        "Then, make a second plot showing the fractional difference of the two times (found-true/true) versus the true time.\n",
        "\n",
        "How well does the results of this crude method compare to a perfect algorithm? Select the best answer below:\n",
        "\n",
        "- The crude method is an almost exact match to the ideal algorithm.\n",
        "\n",
        "- The crude method mostly gets the time at which the signal event occurs and occasionally overestimates/underestimates.\n",
        "\n",
        "- The crude method largely underestimates the time at which the signal event occurs but occasionally gets close or overestimates.\n",
        "\n",
        "- The crude method largely overestimates the time at which the signal event occurs but occasionally gets close or underestimates.\n",
        "\n",
        "- The crude method always underestimates the time at which the signal event occurs.\n",
        "\n",
        "- The crude method always overestimates the time at which the signal event occurs.\n",
        "\n",
        "- The crude method almost never gets the right answer. \n",
        "\n",
        "- The crude method doesn't work at all.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc3d9225",
      "metadata": {
        "tags": [
          "draft",
          "py",
          "learner_chopped"
        ],
        "id": "fc3d9225"
      },
      "outputs": [],
      "source": [
        "#>>>PROBLEM: P2.1.3\n",
        "# Use this cell for drafting your solution (if desired),\n",
        "# then enter your solution in the interactive problem online to be graded.\n",
        "\n",
        "true_times = np.linspace(50, 100, 50)\n",
        "xi = np.arange(0, 128, SAMPLE_SPACING)\n",
        "yi_noise = generate_noise(xi)\n",
        "\n",
        "plt.plot(true_times, get_max_times(xi, yi_noise, true_times,iCheck=True), label = 'naive model')\n",
        "\n",
        "#YOUR CODE HERE\n",
        "\n",
        "plt.xlabel('True Times (s)')\n",
        "plt.ylabel('Found Times (s)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f40a1a7",
      "metadata": {
        "tags": [
          "learner",
          "md",
          "learner_chopped"
        ],
        "id": "0f40a1a7"
      },
      "source": [
        "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 2.1.4</span>\n",
        "\n",
        "Finally, let's make the problem more challenging by scaling the injected merger signal down by a factor of 20. What happens to the crude method in this case? Select the best answer below:\n",
        "\n",
        "- The crude method is an almost exact match to the ideal algorithm.\n",
        "\n",
        "- The crude method largely underestimates the time at which the signal event occurs but occasionally gets close or overestimates.\n",
        "\n",
        "- The crude method largely overestimates the time at which the signal event occurs but occasionally gets close or underestimates.\n",
        "\n",
        "- The crude method always underestimates the time at which the signal event occurs.\n",
        "\n",
        "- The crude method always overestimates the time at which the signal event occurs.\n",
        "\n",
        "- The crude method almost never gets the right answer. \n",
        "\n",
        "- The crude method doesn't work at all."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed944edd",
      "metadata": {
        "tags": [
          "draft",
          "py",
          "learner_chopped"
        ],
        "id": "ed944edd"
      },
      "outputs": [],
      "source": [
        "#>>>PROBLEM: P2.1.4\n",
        "# Use this cell for drafting your solution (if desired),\n",
        "# then enter your solution in the interactive problem online to be graded.\n",
        "\n",
        "true_times = np.linspace(50, 100, 50)\n",
        "xi = np.arange(0, 128, SAMPLE_SPACING)\n",
        "yi_noise = generate_noise(xi)\n",
        "\n",
        "# Modify the following to scale the signal down by a factor of 20, compare the the ideal model\n",
        "#plt.plot(true_times, get_max_times(xi, yi_noise, true_times), label = 'naive model')\n",
        "plt.plot(true_times, true_times, color='red', label='ideal model')\n",
        "plt.xlabel('True Times (s)')\n",
        "plt.ylabel('Found Times (s)')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83cf2f37",
      "metadata": {
        "tags": [
          "learner",
          "md",
          "learner_chopped"
        ],
        "id": "83cf2f37"
      },
      "source": [
        "<a name='section_6_2'></a>\n",
        "<hr style=\"height: 1px;\">\n",
        "\n",
        "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">P2.2 Fitting in the Time Domain: Part I</h2>    \n",
        "\n",
        "| [Top](#section_6_0) | [Previous Section](#section_6_1) | [Problems](#problems_6_2) | [Next Section](#section_6_3) |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "998cf0d8",
      "metadata": {
        "tags": [
          "learner",
          "md"
        ],
        "id": "998cf0d8"
      },
      "source": [
        "<h3>Overview</h3>\n",
        "\n",
        "In the remaining questions below, you will continue investigating the process of extracting signal parameters using a more sophisticated algorithm, called matched filtering. Matched filtering in the time domain is one of the conceptually easiest examples of this technique. Specifically, we'll fit some noisy data with the actual merger signal function itself, with the goal of finding the time at which the signal event occurred. This is one of the more difficult problems of the course.\n",
        "\n",
        "The whole procedure involves forcing the model function to assume a merger time of $t$ (this is the time of maximum amplitude, what we've called `TRUE_TIME`). Rather than trying to find a best fit value of $t$, we will simply scan across a range of values to extract the quality of the fit as a function of $t$. Ideally, we expect a very good fit quality when $t$ is close to the true time, and poor fits away from that value.\n",
        "\n",
        "In the process of trying matched filtering, we'll also investigate how to determine the \"quality\" of a fit and, in particular, the impact of what we use for the uncertainties in the data.\n",
        "\n",
        "An important limitation of the fits used below is that they only include the merger signal function itself. For now, we will not make any attempt to fit the noise terms that are added to the signal.\n",
        "\n",
        "First, let's generate the data we will use in this process. Here, we return to the much simpler case where there are only 10 sinusoidal terms of added noise and the signal is not scaled down. As we saw before, simply finding the point of maximum amplitude in the total signal will indicate the merger signal true time quite reliably. We'll investigate how well matched filtering works at finding this true time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11128a28",
      "metadata": {
        "tags": [
          "learner",
          "py",
          "learner_chopped"
        ],
        "id": "11128a28"
      },
      "outputs": [],
      "source": [
        "#>>>RUN: P2.2-runcell01\n",
        "\n",
        "np.random.seed(0x98a09fe)\n",
        "\n",
        "def complicated_model_fn(x, time, lambda_plus, lambda_minus, max_amp, omega_0, omega_max, omega_sigma):\n",
        "    omega = (omega_max - omega_0) * (np.exp(-np.minimum(x - time, 0)**2 / omega_sigma)) + omega_0\n",
        "    lambdas = np.array([lambda_plus if xvalue > time else lambda_minus for xvalue in x])\n",
        "    amplitude = max_amp * np.exp(-abs(x - time) / lambdas)\n",
        "    return amplitude * np.cos(omega * (x-time))\n",
        "\n",
        "\n",
        "LAMBDA_PLUS_TRUE = 1.0\n",
        "LAMBDA_MINUS_TRUE = 4\n",
        "MAX_AMP_TRUE = 1.2\n",
        "OMEGA_0_TRUE = 3.0\n",
        "OMEGA_MAX_TRUE = 6.0\n",
        "OMEGA_SIGMA_TRUE = 4.0\n",
        "TIME_TRUE = 50.0\n",
        "\n",
        "xi = np.linspace(TIME_TRUE-15, TIME_TRUE+5, 200)\n",
        "yi_true = complicated_model_fn(xi, TIME_TRUE, LAMBDA_PLUS_TRUE, LAMBDA_MINUS_TRUE, MAX_AMP_TRUE,\n",
        "                               OMEGA_0_TRUE, OMEGA_MAX_TRUE, OMEGA_SIGMA_TRUE)\n",
        "\n",
        "NUMBER_SINES_TO_ADD = 10\n",
        "\n",
        "noise_frequencies = 0.5 + 7 * np.random.random(NUMBER_SINES_TO_ADD)\n",
        "noise_phases = 2 * np.pi * np.random.random(NUMBER_SINES_TO_ADD)\n",
        "noise_amplitudes = 2 * MAX_AMP_TRUE / NUMBER_SINES_TO_ADD * np.random.random(NUMBER_SINES_TO_ADD)\n",
        "    # The above line sets noise amplitudes so that the sum of all the noise amplitudes is on average\n",
        "    # equal to the maximum amplitude of the signal.\n",
        "\n",
        "plt.plot(xi, yi_true)\n",
        "plt.title(\"True Signal\")\n",
        "plt.xlabel(\"Time (s)\")\n",
        "plt.ylabel(\"Strain\")\n",
        "plt.show()\n",
        "\n",
        "sample_spacing = 0.1\n",
        "xi = np.arange(-128, 128, sample_spacing)#times\n",
        "yi = np.zeros_like(xi)#data\n",
        "\n",
        "#Adding Noise\n",
        "for freq, phase, amplitude in zip(noise_frequencies, noise_phases, noise_amplitudes):\n",
        "    yi += amplitude * np.sin(phase + freq * xi)\n",
        "\n",
        "#Adding Data\n",
        "signal= complicated_model_fn(xi, TIME_TRUE, LAMBDA_PLUS_TRUE, LAMBDA_MINUS_TRUE, MAX_AMP_TRUE,\n",
        "                               OMEGA_0_TRUE, OMEGA_MAX_TRUE, OMEGA_SIGMA_TRUE)\n",
        "yi+=signal\n",
        "\n",
        "\n",
        "plt.figure(figsize=(16, 5))\n",
        "plt.plot(xi, yi)\n",
        "plt.plot(xi, signal)\n",
        "plt.title(\"Signal plus noise\")\n",
        "plt.xlabel(\"Time (s)\")\n",
        "plt.ylabel(\"Strain\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(xi, yi)\n",
        "plt.plot(xi, signal)\n",
        "plt.title(\"Signal plus noise\")\n",
        "plt.xlim(35,55)\n",
        "plt.xlabel(\"Time (s)\")\n",
        "plt.ylabel(\"Strain\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64c9d1db",
      "metadata": {
        "tags": [
          "learner",
          "md",
          "learner_chopped"
        ],
        "id": "64c9d1db"
      },
      "source": [
        "<a name='problems_6_2'></a>     \n",
        "\n",
        "| [Top](#section_6_0) | [Restart Section](#section_6_2) | [Next Section](#section_6_3) |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26203110",
      "metadata": {
        "tags": [
          "learner",
          "md",
          "learner_chopped"
        ],
        "id": "26203110"
      },
      "source": [
        "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 2.2.1</span>\n",
        "\n",
        "Since the signal waveform has a limited extent before and after the time of maximum amplitude, it's clear that fitting all of the data with just the merger signal function will fail miserably. Rather, we'll need to select a subset of the data to perform the fit. How much time before and after the time of maximum signal $t$ do you think the fit should include? We really only need to consider the region where the signal is rather large and therefore will be more easily separated from the noise. In practice this is something we could find systematically, for example by analyzing the data close to and far from the maximum signal point. However, for now, read the guidance below to choose an appropriate window.\n",
        "\n",
        "In what follows, only consider a 7-9 second long window, as this will include enough data to make our fits converge, but will still give few enough data points that the fits converge relatively fast. Furthermore, this window need not be symmetric around $t$, as much of the signal lies before the true time with only a short period of signal after $t$. Therefore, we want the number of earlier seconds to include (`t_before`) to be larger than the following time span (`t_after`).\n",
        "\n",
        "With these conditions, one possible choice for `[t_before, t_after]` is `[5,2]`. What is another acceptable answer, given the constraints that we outlined?\n",
        "\n",
        "Enter your answer as a list, formatted as `[t_before, t_after]`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2210b3a",
      "metadata": {
        "tags": [
          "learner",
          "md",
          "learner_chopped"
        ],
        "id": "d2210b3a"
      },
      "source": [
        "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 2.2.2</span>\n",
        "\n",
        "In order to fit the signal waveform to a set of data, we need to write a function `model_and_random_parameters(t)` that creates an `lmfit` `Model` and associated `Parameters` for  `complicated_model_fn`. As discussed above, we want to force the time of the signal to appear at an input time `t`.  To limit the range that the fit considers, we also want to constrain the parameters, with limits in the dictionary `params_min_max`. the initial values of the parameters should be chosen randomly within those given ranges.\n",
        "\n",
        "Complete the function `get_param_random_value` in the code below so that it choses random starting points for the parameters which are uniformly distributed between `p_min` and `p_max`.\n",
        "\n",
        "To check if you've done this correctly, the lines at the end of the code print out the value of one of the parameters. With the given starting seed, the answer should be about 1.51. Test this in your notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b88f143",
      "metadata": {
        "tags": [
          "draft",
          "py",
          "learner_chopped"
        ],
        "id": "0b88f143"
      },
      "outputs": [],
      "source": [
        "#>>>PROBLEM: P2.2.2\n",
        "# Use this cell for drafting your solution (if desired),\n",
        "# then enter your solution in the interactive problem online to be graded.\n",
        "\n",
        "from lmfit import Model, Parameters\n",
        "    \n",
        "    \n",
        "def get_param_random_value(p_min,p_max):\n",
        "    #get a uniformly distributed random value between p_min and p_max\n",
        "    #return a float\n",
        "    return #YOUR CODE HERE\n",
        "\n",
        "\n",
        "params_min_max = {\n",
        "    'lambda_plus': (0.1, 5),\n",
        "    'lambda_minus': (0.1, 5),\n",
        "    'max_amp': (0, 2),\n",
        "    'omega_0': (0, 5),\n",
        "    'omega_max': (0, 10),\n",
        "    'omega_sigma': (0, 5)\n",
        "}\n",
        "\n",
        "def model_and_random_parameters(t):\n",
        "    model = Model(complicated_model_fn)\n",
        "    params = Parameters()\n",
        "    params.add('time', value=t, vary=False)\n",
        "    for p, (p_min, p_max) in params_min_max.items():\n",
        "        value = get_param_random_value(p_min,p_max)\n",
        "        params.add(p, min=p_min, max=p_max, value=value)\n",
        "    return model, params\n",
        "\n",
        "\n",
        "#TEST EXAMPLE: SHOULD = 1.51166\n",
        "t=0.1\n",
        "np.random.seed(1)\n",
        "print(model_and_random_parameters(t)[1].get('omega_0').value)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c9c1e96",
      "metadata": {
        "tags": [
          "learner",
          "md",
          "learner_chopped"
        ],
        "id": "9c9c1e96"
      },
      "source": [
        "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 2.2.3</span>\n",
        "\n",
        "The code below includes a function `fit_once` that fits the model created in the previous problem and outputs the fit result. Remember that we only want to look at a limited subset of the data when we fit, namely the range `(t-t_before, t+t_after)`, where `t` is the specific time at which we want to look for the signal. This version uses the values `t_before = 5` and `t_after = 2`. \n",
        "\n",
        "You need to write a function `get_signal_indices` which returns the indices in the data arrays which correspond to this range of times. HINT: You may find the function `np.where()` useful.\n",
        "\n",
        "Optionally print the $\\chi^2$ result or the fit report. Note, that since a random seed is not defined, you may get different results each time you run. This is the point of choosing random initial parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "415a162c",
      "metadata": {
        "tags": [
          "draft",
          "py",
          "learner_chopped"
        ],
        "id": "415a162c"
      },
      "outputs": [],
      "source": [
        "#>>>PROBLEM: P2.2.3\n",
        "# Use this cell for drafting your solution (if desired),\n",
        "# then enter your solution in the interactive problem online to be graded.\n",
        "import lmfit\n",
        "\n",
        "#THE WINDOW MUST BE [5,2] FOR YOUR ANSWER TO MATCH EXPECTED VALUES\n",
        "t_before = 5\n",
        "t_after = 2\n",
        "\n",
        "\n",
        "def get_signal_indices(xi, t, t_before, t_after):\n",
        "    #use np.where() to return a 1D the relevant indices\n",
        "    #note, the result of np.where() will be a tuple\n",
        "    return #YOUR CODE HERE\n",
        "\n",
        "def fit_once(xi, yi, t, t_before, t_after):\n",
        "    data_indices = get_signal_indices(xi, t, t_before, t_after)\n",
        "    data_x = xi[data_indices]\n",
        "    data_y = yi[data_indices]\n",
        "    model, params = model_and_random_parameters(t)    \n",
        "    result = model.fit(data_y, params, x=data_x)\n",
        "    return result\n",
        "\n",
        "result = fit_once(xi, yi, TIME_TRUE, t_before, t_after)\n",
        "result.plot();\n",
        "\n",
        "#print(\"Fit chi2 value: \", result.chisqr)\n",
        "#print(\"Fit chi2 probability: \",1-stats.chi2.cdf(result.chisqr,result.nfree))\n",
        "#print(result.fit_report())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d6fc3e4",
      "metadata": {
        "tags": [
          "learner",
          "md",
          "learner_chopped"
        ],
        "id": "8d6fc3e4"
      },
      "source": [
        "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 2.2.4</span>\n",
        "\n",
        "Run the fit multiple times and print the $\\chi^{2}$ value and $\\chi^{2}$ probability using the following lines of code.\n",
        "\n",
        "<pre>\n",
        "print(\"Fit chi2 value: \", result.chisqr)\n",
        "print(\"Fit chi2 probability: \",1-stats.chi2.cdf(result.chisqr,result.nfree))\n",
        "</pre>\n",
        "\n",
        "What is the lowest $\\chi^{2}$ value that you obtain, and its corresponding $\\chi^{2}$ probability?\n",
        "\n",
        "Enter your answer as a list of numbers `[chi2, chi2_prob]` with precision 1e-3."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "305296c8",
      "metadata": {
        "tags": [
          "learner",
          "md",
          "learner_chopped"
        ],
        "id": "305296c8"
      },
      "source": [
        "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 2.2.5</span>\n",
        "\n",
        "\n",
        "Let's consider whether the best $\\chi^{2}$ value and its probability are reasonable numbers. In particular, what does the $\\chi^{2}$ probability say about the fit? Choose the best answer from the following options:\n",
        "\n",
        "- The fit is perfect! This is because our model is perfect. Our job is done.\n",
        "- The fit is too perfect, which means we should carefully consider the assumptions we have made.\n",
        "- The fit is okay, and we can do no better.\n",
        "- The fit is terrible, so we should adjust our model or the range of data that we are fitting.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fac33c58",
      "metadata": {
        "tags": [
          "draft",
          "py",
          "learner_chopped"
        ],
        "id": "fac33c58"
      },
      "outputs": [],
      "source": [
        "#>>>PROBLEM: P2.2.5\n",
        "# Use this cell for drafting your solution (if desired),\n",
        "# then enter your solution in the interactive problem online to be graded.\n",
        "import scipy.stats as stats\n",
        "\n",
        "print(\"Fit chi2 probability: \",1-stats.chi2.cdf(result.chisqr,result.nfree))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3297a453",
      "metadata": {
        "tags": [
          "learner",
          "md",
          "learner_chopped"
        ],
        "id": "3297a453"
      },
      "source": [
        "<a name='section_6_3'></a>\n",
        "<hr style=\"height: 1px;\">\n",
        "\n",
        "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">P2.3 Fitting in the Time Domain: Part II</h2>    \n",
        "\n",
        "| [Top](#section_6_0) | [Previous Section](#section_6_2) | [Problems](#problems_6_3) | [Next Section](#section_6_4) |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fcbf6f2",
      "metadata": {
        "tags": [
          "learner",
          "md"
        ],
        "id": "1fcbf6f2"
      },
      "source": [
        "<h3>Weighted Fitting</h3>\n",
        "\n",
        "Our result for the fit in the previous questions suggests that the uncertainties are overestimated, but why? The real issue is that our fit so far has not taken into account the uncertainties correctly. To do that, we need to do a weighed $\\chi^{2}$ fit.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d383d344",
      "metadata": {
        "tags": [
          "learner",
          "md",
          "learner_chopped"
        ],
        "id": "d383d344"
      },
      "source": [
        "<a name='problems_6_3'></a>     \n",
        "\n",
        "| [Top](#section_6_0) | [Restart Section](#section_6_3) | [Next Section](#section_6_4) |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "630f49b6",
      "metadata": {
        "tags": [
          "learner",
          "md",
          "learner_chopped"
        ],
        "id": "630f49b6"
      },
      "source": [
        "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 2.3.1</span>\n",
        "\n",
        "We want to modify the previous fit to use uncertainties with a value of $\\sigma=0.2$. To do this, you will run a \"weighted\" fit with `lmfit` by setting an array of weights. The code below is similar to what you saw above, but now with a function `fit_once_weighted`. You need to complete that function to use $\\sigma=0.2$.\n",
        "\n",
        "Note, the weights in `lmfit` are designed so that $w=1/\\sigma$, leading to the following:\n",
        "\n",
        "$$\\chi^{2} = \\sum_{i}\\frac{(f(x_{i})-f(x))^{2}}{\\sigma_{i}^{2}}$$\n",
        "\n",
        "With this new version of the fit, what is the $\\chi^{2}$ probability corresponding to the lowest $\\chi^{2}$ value ? Enter your answer as a number with precision 1e-3.\n",
        "\n",
        "Hint: As before, you can run the code multiple times or use a `for` loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f11934f",
      "metadata": {
        "tags": [
          "draft",
          "py",
          "learner_chopped"
        ],
        "id": "2f11934f"
      },
      "outputs": [],
      "source": [
        "#>>>PROBLEM: P2.3.1\n",
        "# Use this cell for drafting your solution (if desired),\n",
        "# then enter your solution in the interactive problem online to be graded.\n",
        "import lmfit\n",
        "\n",
        "def fit_once_weighted(xi, yi, t, t_before, t_after, weight=1.0):\n",
        "    data_indices = get_signal_indices(xi, t, t_before, t_after)\n",
        "    data_x = xi[data_indices]\n",
        "    data_y = yi[data_indices]\n",
        "    \n",
        "    weights = #YOUR CODE HERE\n",
        "    \n",
        "    model, params = model_and_random_parameters(t)\n",
        "    result = model.fit(data_y, params, x=data_x,weights=weights)\n",
        "    return result\n",
        "\n",
        "#The window must be [5,2] for your answer to match expected values\n",
        "t_before = 5\n",
        "t_after = 2\n",
        "\n",
        "unc=0.2\n",
        "result = fit_once_weighted(xi, yi, TIME_TRUE, t_before, t_after,1./unc)\n",
        "\n",
        "result.plot();\n",
        "print(\"Fit chi2 value: \", result.chisqr)\n",
        "print(\"Fit chi2 probability: \",1-stats.chi2.cdf(result.chisqr,result.nfree))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a606b23",
      "metadata": {
        "tags": [
          "learner",
          "md",
          "learner_chopped"
        ],
        "id": "1a606b23"
      },
      "source": [
        "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 2.3.2</span>\n",
        "\n",
        "The choice of $\\sigma=0.2$ in the previous problem was totally arbitrary. Can we come up with a strategy to compute a more realistic uncertainty for our data?  With LIGO data, this is a difficult question, since much of the wiggles from the \"Noise\" are actually understood as oscillations at certain frequencies. \n",
        "\n",
        "For now, we won't model the noise, but instead, we'll calculate uncertainties that reflect the average RMS of our noisy data by using a  signal-free region of time. \n",
        "\n",
        "The code below computes the standard deviation of the signal-free noise, but it needs to know what time range to use for that calculation. You need to complete the function `get_noise_indices` and then repeat the fit. In your noise calculation, only exclude the region that is considered in the fit.\n",
        "\n",
        "What $\\chi^{2}$ probability do you get, corresponding to the lowest $\\chi^{2}$ value? Again, run your code multiple times to obtain the min value. Enter your answer **for the $\\chi^{2}$ probability** as a number with precision 1e-3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c388698",
      "metadata": {
        "tags": [
          "draft",
          "py",
          "learner_chopped"
        ],
        "id": "5c388698"
      },
      "outputs": [],
      "source": [
        "#>>>PROBLEM: P2.3.2\n",
        "# Use this cell for drafting your solution (if desired),\n",
        "# then enter your solution in the interactive problem online to be graded.\n",
        "import lmfit\n",
        "\n",
        "def get_noise_indices(xi, t, t_before, t_after):\n",
        "    return #YOUR CODE HERE\n",
        "    \n",
        "\n",
        "def noise(xi, yi, t, t_before, t_after):\n",
        "    data_indices = get_noise_indices(xi, t, t_before, t_after)\n",
        "    data_y = yi[data_indices]\n",
        "    return np.std(data_y)\n",
        "\n",
        "t_before = 5\n",
        "t_after = 2\n",
        "\n",
        "unc=noise(xi, yi, TIME_TRUE, t_before, t_after)\n",
        "result = fit_once_weighted(xi, yi, TIME_TRUE, t_before, t_after,1./unc)\n",
        "result.plot();\n",
        "print(\"unc value: \", unc)\n",
        "print(\"Fit chi2 value: \", result.chisqr)\n",
        "print(\"Fit chi2 probability: \",1-stats.chi2.cdf(result.chisqr,result.nfree))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b32d0e92",
      "metadata": {
        "tags": [
          "md",
          "learner"
        ],
        "id": "b32d0e92"
      },
      "source": [
        "<h3>Correlations</h3>\n",
        "\n",
        "Our fit is, in some sense, still too good! Why is this the case? Well, what is happening in this case is that our fit is trying to match both the signal and the noise using a function that includes only the merger waveform. This is partly a feature of fitting time series data, where the noise causes the deviations of points from the signal waveform to be correlated with one another. For example, a point is very likely to be below the expected value if the previous point was low because the noise caused a downward fluctuation. This effect is quite obvious in the various residual plots. The calculation of $\\chi^{2}$ in `lmfit` assumes that the data fluctuate randomly, with each point's deviation independent of the previous point.\n",
        "\n",
        "To get a better estimate of the quality of the fit, we can imagine taking every other point or trying to compute the point to point variation, by taking the difference between consecutive points, or even points that are a little farther away. The larger the delta-t of our RMS, the less assumptions we are making about our ability to model background noise. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dfae661",
      "metadata": {
        "tags": [
          "md",
          "learner"
        ],
        "id": "8dfae661"
      },
      "source": [
        "<h3>Two Options for Addressing Correlations</h3>\n",
        "\n",
        "Try running the cells below. In the first case, nearest-neighbor data are averaged and the data are fit again. In the second case, the noise is estimated from differences in points that are 2 time-steps away. Do you think these are reasonable attempts to account for the correlated nature of the data?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d95fd7e0",
      "metadata": {
        "tags": [
          "learner",
          "py",
          "learner_chopped"
        ],
        "id": "d95fd7e0"
      },
      "outputs": [],
      "source": [
        "#>>>RUN: P2.3-runcell01\n",
        "\n",
        "#Computing uncertainty: merging bins\n",
        "\n",
        "xi_old = xi.copy()\n",
        "yi_old = yi.copy()\n",
        "xi_new = np.array([ 0.5*(xi_old[2*i]+xi_old[2*i+1]) for i in range(len(xi_old)//2) ])\n",
        "yi_new = np.array([ 0.5*(yi_old[2*i]+yi_old[2*i+1]) for i in range(len(yi_old)//2) ])\n",
        "\n",
        "t_before = 5\n",
        "t_after = 2\n",
        "\n",
        "uncout=noise(xi_new, yi_new, TIME_TRUE, t_before, t_after)\n",
        "result = fit_once_weighted(xi_new, yi_new, TIME_TRUE, t_before, t_after,1./uncout)\n",
        "result.plot();\n",
        "print(\"unc value: \", uncout)\n",
        "print(\"Fit chi2 value: \", result.chisqr)\n",
        "print(\"Fit chi2 probability: \",1-stats.chi2.cdf(result.chisqr,result.nfree))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94a59016",
      "metadata": {
        "tags": [
          "learner",
          "py",
          "learner_chopped"
        ],
        "id": "94a59016"
      },
      "outputs": [],
      "source": [
        "#>>>RUN: P2.3-runcell02\n",
        "\n",
        "#Computing uncertainty: points 2 samples away\n",
        "\n",
        "def noise_deltat(xi, yi, t, t_before, t_after, dt=2):#dt is the size distance of the samples\n",
        "    data_indices = get_noise_indices(xi, t, t_before, t_after)\n",
        "    #print(data_indices[0][:-dt],data_indices[0][dt:])\n",
        "    data_y = yi[data_indices[0][:-dt]]-yi[data_indices[0][dt:]]\n",
        "    return np.std(data_y)\n",
        "\n",
        "t_before = 5\n",
        "t_after = 2\n",
        "\n",
        "uncout=noise_deltat(xi_old, yi_old, TIME_TRUE, t_before, t_after)\n",
        "result = fit_once_weighted(xi_old, yi_old, TIME_TRUE, t_before, t_after,1./uncout)\n",
        "result.plot();\n",
        "print(\"unc value: \", uncout)\n",
        "print(\"Fit chi2 value: \", result.chisqr)\n",
        "print(\"Fit chi2 probability: \",1-stats.chi2.cdf(result.chisqr,result.nfree))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "550e9c62",
      "metadata": {
        "tags": [
          "learner",
          "md",
          "learner_chopped"
        ],
        "id": "550e9c62"
      },
      "source": [
        "<a name='section_6_4'></a>\n",
        "<hr style=\"height: 1px;\">\n",
        "\n",
        "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">P2.4 Sweeping the Time Window</h2>   \n",
        "\n",
        "| [Top](#section_6_0) | [Previous Section](#section_6_3) | [Problems](#problems_6_4) | [Next Section](#section_7_1) |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d716ae7",
      "metadata": {
        "tags": [
          "learner",
          "md"
        ],
        "id": "6d716ae7"
      },
      "source": [
        "<h3>Overview</h3>\n",
        "\n",
        "From the analysis above, we see that an uncertainty of 0.18 gave a more reasonable $\\chi^2$ probability. This was found for `dt=2`, which should limit the assumptions we are making about the nature of the background noise.\n",
        "\n",
        "Let's redefine `fit_once` using this uncertainty. Run the code below several times. Does it always find the lowest $\\chi^2$ value?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71f757d6",
      "metadata": {
        "scrolled": false,
        "tags": [
          "py",
          "learner",
          "learner_chopped"
        ],
        "id": "71f757d6"
      },
      "outputs": [],
      "source": [
        "#>>>RUN: P2.4-runcell01\n",
        "\n",
        "#From the above analysis, we see that an uncertainty of 0.18 is more reasonable.\n",
        "#This was found for deltat = 2, which should limit that assumptions we are making\n",
        "#about the nature of the background noise\n",
        "\n",
        "#Let's try using this uncertainty\n",
        "\n",
        "\n",
        "def fit_once_new(t, t_before, t_after, weight=1.0):\n",
        "    data_indices = get_signal_indices(xi, t, t_before, t_after)\n",
        "    data_x = xi[data_indices]\n",
        "    data_y = yi[data_indices]\n",
        "    weights = np.ones(len(data_x))*weight\n",
        "    model, params = model_and_random_parameters(t)\n",
        "    result = model.fit(data_y, params, x=data_x,weights=weights)\n",
        "    return result\n",
        "\n",
        "t_before = 5\n",
        "t_after = 2\n",
        "\n",
        "unc=0.18\n",
        "result = fit_once_new(TIME_TRUE, t_before, t_after, 1.0/unc)\n",
        "result.plot();\n",
        "print(\"Fit chi2 value: \", result.chisqr)\n",
        "print(\"Fit chi2 probability: \",1-stats.chi2.cdf(result.chisqr,result.nfree))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "802d2214",
      "metadata": {
        "tags": [
          "md",
          "learner"
        ],
        "id": "802d2214"
      },
      "source": [
        "We see that the function with a fixed uncertainty of 0.18 gets the lowest $\\chi^2$ often, but not every time and, therefore, it's not guaranteed to find the best fit on the first try. So, instead of `fit_once_new`, we'll use a new function called `fit`, which runs `fit_once_new` multiple times and outputs the best (lowest $\\chi^2$) result."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ebaf9b1",
      "metadata": {
        "tags": [
          "learner",
          "md",
          "learner_chopped"
        ],
        "id": "6ebaf9b1"
      },
      "source": [
        "<a name='problems_6_4'></a>     \n",
        "\n",
        "| [Top](#section_6_0) | [Restart Section](#section_6_4) |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5e47478",
      "metadata": {
        "tags": [
          "learner",
          "md",
          "learner_chopped"
        ],
        "id": "d5e47478"
      },
      "source": [
        "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 2.4.1</span>\n",
        "\n",
        "In the code below, the function `fit_once_new` from above is run multiple times. Complete the code to find the best result in the list and return it. Specifically, modify the `get_min_result` function. \n",
        "\n",
        "What is the lowest $\\chi^2$ value and its corresponding probability? Enter your answer as a list of numbers `[chi2, chi2_prob]` with precision 1e-3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d557c62",
      "metadata": {
        "scrolled": false,
        "tags": [
          "draft",
          "py",
          "learner_chopped"
        ],
        "id": "7d557c62"
      },
      "outputs": [],
      "source": [
        "#>>>PROBLEM: P2.4.1\n",
        "# Use this cell for drafting your solution (if desired),\n",
        "# then enter your solution in the interactive problem online to be graded.\n",
        "\n",
        "def get_min_result(results):\n",
        "    min_result = None\n",
        "    min_chisq = None\n",
        "    #for each result in results, set a new min_result and min_chisq\n",
        "    #if result.chisqr is less than the currently stored value\n",
        "    \n",
        "    #YOUR CODE HERE\n",
        "    \n",
        "    return min_result\n",
        "\n",
        "NUM_FITS = 10\n",
        "\n",
        "def fit_many(t, t_before, t_after, weight, num):\n",
        "  results=[]\n",
        "  for i in range(num):\n",
        "    results.append(fit_once_new(t, t_before, t_after, weight))\n",
        "\n",
        "  min_result = get_min_result(results)\n",
        "  return min_result\n",
        "\n",
        "t_before = 5\n",
        "t_after = 2\n",
        "unc=0.18\n",
        "\n",
        "min_result = fit_many(TIME_TRUE, t_before, t_after, 1.0/unc, NUM_FITS)\n",
        "\n",
        "min_result.plot();\n",
        "print(\"Fit chi2 value: \", min_result.chisqr)\n",
        "print(\"Fit chi2 probability: \",1-stats.chi2.cdf(min_result.chisqr,min_result.nfree))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b32a9662",
      "metadata": {
        "tags": [
          "learner",
          "md",
          "learner_chopped"
        ],
        "id": "b32a9662"
      },
      "source": [
        "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 2.4.2</span>\n",
        "\n",
        "Next, we want to see what the fits look like for different `t` values. The code cell below calls `fit_many` for values of $t \\in [-100, 100]$, where the $t$ values are separated by $\\Delta t = 1 \\mathrm{s}$ and stores all of the fit outputs in an array named `results`. The code is complete, you just need to run it.\n",
        "\n",
        "How long does it take to do this? (pick the closest answer)\n",
        "\n",
        "A. .01 seconds\n",
        "\n",
        "B. 1 second\n",
        "\n",
        "C. 5 minutes\n",
        "\n",
        "D. 5 hours (if this is the answer you pick **something is wrong**)\n",
        "\n",
        "E. 10 days (if this is the answer you pick **something is wrong**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb62db10",
      "metadata": {
        "tags": [
          "py",
          "learner",
          "learner_chopped"
        ],
        "id": "eb62db10"
      },
      "outputs": [],
      "source": [
        "#>>>RUN: P2.4.2\n",
        "%%time\n",
        "\n",
        "results = []\n",
        "delta_t = 1\n",
        "ts = np.arange(-100, 100, delta_t)\n",
        "\n",
        "t_before = 5\n",
        "t_after = 2\n",
        "unc=0.18\n",
        "\n",
        "NUM_FITS = 6\n",
        "\n",
        "for t in ts:\n",
        "  if t % 20 == 0: print(t)\n",
        "  results.append(fit_many(t, t_before, t_after, 1.0/unc, NUM_FITS))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a72bffa0",
      "metadata": {
        "tags": [
          "learner",
          "md",
          "learner_chopped"
        ],
        "id": "a72bffa0"
      },
      "source": [
        "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 2.4.3</span>\n",
        "\n",
        "Now we need to find out for which $t$ value we get a fit that is most likely to be our signal. One way of figuring this out is by looking for which fit has the largest `max_amp` parameter, as the signal will have a higher max amplitude than the surrounding noise.\n",
        "\n",
        "Plot `max_amp` as a function of $t$ given the `results` you just calculated. Find the value of $t$ which has the largest `max_amp` and plot the corresponding fit result.\n",
        "\n",
        "Does the fit look like it could be the signal we're looking for? If yes, then enter below at what value of $t$ this was. If not, keep searching through the next highest `max_amp` values till you get something that may be signal and answer that $t$ value below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f76ad79a",
      "metadata": {
        "tags": [
          "draft",
          "py",
          "learner_chopped"
        ],
        "id": "f76ad79a"
      },
      "outputs": [],
      "source": [
        "#>>>PROBLEM: P2.4.3\n",
        "# Use this cell for drafting your solution (if desired),\n",
        "# then enter your solution in the interactive problem online to be graded.\n",
        "\n",
        "amps = #LIST OF MAXIMUM AMPLITUDES\n",
        "result_max_amp = #RESULT CORRESPONDING TO MAX AMP\n",
        "\n",
        "result_max_amp.plot()\n",
        "print(\"Time of best fit result: \", ts[np.argmax(amps)])\n",
        "plt.show()\n",
        "\n",
        "plt.plot(ts, amps)\n",
        "plt.xlabel(\"Time(s)\")\n",
        "plt.ylabel(\"Wave amplitudes\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "514feb8b",
      "metadata": {
        "tags": [
          "learner",
          "md"
        ],
        "id": "514feb8b"
      },
      "source": [
        "<h3>Why Not Use the Minimum Chisq Value?</h3>\n",
        "\n",
        "You might wonder why we chose to look for the maximum amplitude instead of the lowest $\\chi^2$. The code shown below does the latter. Does the smallest chi-sq value give you the same t value that you found previously? Why or why not? What other criteria could you use to search for the signal?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "147f8ea7",
      "metadata": {
        "scrolled": false,
        "tags": [
          "py",
          "learner",
          "learner_chopped"
        ],
        "id": "147f8ea7"
      },
      "outputs": [],
      "source": [
        "#>>>RUN: P2.4-runcell02\n",
        "\n",
        "chi2 = [r.chisqr for r in results]\n",
        "min_result=results[np.argmin(chi2)]\n",
        "min_result.plot()\n",
        "print(\"Time of best fit result: \", ts[np.argmin(chi2)],\" with lowest chi^2: \",min_result.chisqr)\n",
        "plt.show()\n",
        "\n",
        "plt.plot(ts, chi2)\n",
        "plt.xlabel(\"Time(s)\")\n",
        "plt.ylabel(\"Wave $\\chi^{2}$\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f4b3bb9",
      "metadata": {
        "tags": [
          "learner",
          "md"
        ],
        "id": "6f4b3bb9"
      },
      "source": [
        "As you can see, the fit with the minimum $\\chi^2$ is not at the correct input signal time.\n",
        "\n",
        "When we are fitting data, we are floating all the parameters of the fit, including amplitude. Our fit function is really quite complicated, so it's flexible enough to fit some areas of the noise.  Hence, low values of $\\chi^{2}$ can occur in any area where the noise randomly matches enough aspects of the signal waveform to give a reasonable fit. As a result, there are many local minima and the global minimum turns out to be far away from the true signal time. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "485c7591",
      "metadata": {
        "tags": [
          "learner",
          "md"
        ],
        "id": "485c7591"
      },
      "source": [
        "<h3>How Can We Do Better?</h3>\n",
        "\n",
        "This fit took a while to run and there doesn't seem to be an unambiguously ideal way to find the right answer in the array of results. In practice, it would be better for searches like this to run quickly and produce a more reliable answer, so that if a wave event is detected, an alert can be sent out to telescopes all over the world and they can look at the correct area of the sky with minimal delay. How could you make this process faster and more robust, aside from running it on better hardware?\n",
        "\n",
        "Some options include:\n",
        "    \n",
        "- Constrain parameters of the model to realistic values so that you're fitting with fewer degrees of freedom\n",
        "- Delve into the minimization software and tell it to halt if it's in a local minimum and not near the global minimum by checking if the chi-squared is unusually large. \n",
        "- Don't perform a full fit; compare to some template or set of templates and plot the chi squared\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2049923",
      "metadata": {
        "tags": [
          "learner",
          "md"
        ],
        "id": "e2049923"
      },
      "source": [
        "<h3> Moving Onward!</h3>\n",
        "\n",
        "One possibility to explore is whether there is a better procedure that doesn't use the time domain! We will explore that next.    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a456152d",
      "metadata": {
        "tags": [
          "learner",
          "md",
          "learner_chopped"
        ],
        "id": "a456152d"
      },
      "source": [
        "<a name='section_7_1'></a>\n",
        "<hr style=\"height: 1px;\">\n",
        "\n",
        "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">P2.5 Introduction to Fitting in the Frequency Domain</h2>   \n",
        "\n",
        "| [Top](#section_6_0) | [Previous Section](#section_6_4) | [Next Section](#section_7_2) |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f724f796",
      "metadata": {
        "tags": [
          "learner",
          "md",
          "learner_chopped"
        ],
        "id": "f724f796"
      },
      "source": [
        "<h3>Importing Data (Colab Only)</h3>\n",
        "\n",
        "If you are in a Google Colab environment, run the cell below to import the data for this notebook. Otherwise, if you have downloaded the course repository, you do not have to run the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a24b3d05",
      "metadata": {
        "tags": [
          "learner",
          "py",
          "learner_chopped"
        ],
        "id": "a24b3d05"
      },
      "outputs": [],
      "source": [
        "#>>>RUN: P2.5-runcell000\n",
        "\n",
        "!git init\n",
        "!git remote add -f origin https://github.com/mitx-8s50/nb_LEARNER/\n",
        "!git config core.sparseCheckout true\n",
        "!echo 'data/P06' >> .git/info/sparse-checkout\n",
        "!git pull origin main"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "008c6b96",
      "metadata": {
        "tags": [
          "learner",
          "md"
        ],
        "id": "008c6b96"
      },
      "source": [
        "<h3>Importing Libraries</h3>\n",
        "\n",
        "Before beginning, run the cell below to import the relevant libraries for this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e6c9d37",
      "metadata": {
        "tags": [
          "learner",
          "py",
          "learner_chopped"
        ],
        "id": "5e6c9d37"
      },
      "outputs": [],
      "source": [
        "#>>>RUN: P2.5-runcell001\n",
        "\n",
        "!pip install lmfit\n",
        "!pip install playsound\n",
        "!pip install soundfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f322bbca",
      "metadata": {
        "tags": [
          "learner",
          "py",
          "learner_chopped"
        ],
        "id": "f322bbca"
      },
      "outputs": [],
      "source": [
        "#>>>RUN: P2.5-runcell002\n",
        "\n",
        "import numpy as np                 #https://numpy.org/doc/stable/\n",
        "import matplotlib.pyplot as plt    #https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.html\n",
        "from scipy.io.wavfile import write   #https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.wavfile.write.html\n",
        "\n",
        "from lmfit import Model, Parameters #https://lmfit.github.io/lmfit-py/parameters.html\n",
        "                                    #https://lmfit.github.io/lmfit-py/model.html#lmfit.model.Model\n",
        "import scipy.stats as stats         #https://docs.scipy.org/doc/scipy/reference/stats.html\n",
        "from scipy.stats import chisquare   #https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chisquare.html"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63ef0aa6",
      "metadata": {
        "tags": [
          "learner",
          "md"
        ],
        "id": "63ef0aa6"
      },
      "source": [
        "<h3>Overview</h3>\n",
        "\n",
        "**Note:** There are no problems in this section. Review and run the cells to understand later sections.\n",
        "\n",
        "Previously, we studied the procedure of fitting in the time domain, including discovering some of its limitations. Now, we're going to do a similar process in the frequency domain. However, instead of performing a fit, we're going to compare the data to a template of a merger signal which we will generate."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c077351d",
      "metadata": {
        "tags": [
          "learner",
          "md"
        ],
        "id": "c077351d"
      },
      "source": [
        "Let's start by making the template in the time domain using the same function as before. The code below creates two sets of y values, one for the same parameters as before (`y_true`), and one with parameters that are similar to the true values but slightly shifted (`y_temp`). Note that the `y_temp` array uses a `TIME_TRUE` value of 0. In the plot, the time for the `y_true` array is shifted so that the two overlap.\n",
        "\n",
        "In what follows, we will call the `y_true` array the \"data\" and the `y_temp` array the \"template\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57841f9f",
      "metadata": {
        "tags": [
          "learner",
          "py",
          "learner_chopped"
        ],
        "id": "57841f9f"
      },
      "outputs": [],
      "source": [
        "#>>>RUN: P2.5-runcell01\n",
        "\n",
        "np.random.seed(0x98a09fe)\n",
        "\n",
        "def complicated_model_fn(x, time, lambda_plus, lambda_minus, max_amp, omega_0, omega_max, omega_sigma):\n",
        "    omega = (omega_max - omega_0) * (np.exp(-np.minimum(x - time, 0)**2 / omega_sigma)) + omega_0\n",
        "    lambdas = np.array([lambda_plus if xvalue > time else lambda_minus for xvalue in x])\n",
        "    amplitude = max_amp * np.exp(-abs(x - time) / lambdas)\n",
        "    return amplitude * np.cos(omega * (x-time))\n",
        "\n",
        "LAMBDA_PLUS_TRUE = 1.0\n",
        "LAMBDA_MINUS_TRUE = 4\n",
        "MAX_AMP_TRUE = 1.2\n",
        "OMEGA_0_TRUE = 3.0\n",
        "OMEGA_MAX_TRUE = 6.0\n",
        "OMEGA_SIGMA_TRUE = 4.0\n",
        "TIME_TRUE = 50.0\n",
        "TIME_SHIFT = -150\n",
        "\n",
        "sample_spacing = 0.1\n",
        "xi       = np.arange(-128, 128, sample_spacing)#times\n",
        "xi_shift = np.arange( -26, 230, sample_spacing)#times\n",
        "\n",
        "yi_temp = complicated_model_fn(xi_shift, 0, 1.5, 3.5, 1.0, 3.2, 5.5, 3.5)\n",
        "yi_true = complicated_model_fn(xi, TIME_TRUE+TIME_SHIFT, LAMBDA_PLUS_TRUE, LAMBDA_MINUS_TRUE, MAX_AMP_TRUE,\n",
        "                               OMEGA_0_TRUE, OMEGA_MAX_TRUE, OMEGA_SIGMA_TRUE)\n",
        "\n",
        "#Alternative approach\n",
        "#template_mask = np.where((xi > -15) & (xi < 5))\n",
        "#data_mask = np.where((xi > TIME_TRUE-15) & (xi < TIME_TRUE+5))#\n",
        "#plt.plot(xi[data_mask]-TIME_TRUE, yi_true[data_mask], label=\"True\")\n",
        "\n",
        "template_mask = np.where((xi > -128) & (xi < 128))\n",
        "data_mask     = np.where((xi > -128) & (xi < 128))\n",
        "plt.plot(xi[data_mask], yi_true[data_mask], label=\"True\")\n",
        "plt.plot(xi[template_mask], yi_temp[template_mask], label=\"Template\")\n",
        "plt.xlabel(\"Time (s)\")\n",
        "plt.ylabel(\"Strain\")\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e13afa4",
      "metadata": {
        "tags": [
          "learner",
          "md"
        ],
        "id": "4e13afa4"
      },
      "source": [
        "In order to work in the frequency domain, we need to start by taking a Fourier transform of our template and data. Curiously, even though the two samples have an identical functional form, as well as very similar input parameters, the FFT outputs are very different, especially for the imaginary parts. As you can see in the 3rd plot, the real parts of the two FFTs also have some differences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1531ef57",
      "metadata": {
        "tags": [
          "learner",
          "py",
          "learner_chopped"
        ],
        "id": "1531ef57"
      },
      "outputs": [],
      "source": [
        "#>>>RUN: P2.5-runcell02\n",
        "\n",
        "fs = int(1/(xi[1] - xi[0]))\n",
        "\n",
        "data_fft = np.fft.fft(yi_true)\n",
        "template_fft = np.fft.fft(yi_temp)\n",
        "\n",
        "freq = np.fft.fftfreq(xi.shape[0])*fs\n",
        "\n",
        "plt.figure(figsize=(16, 5))\n",
        "plt.title(\"FFT of data\")\n",
        "plt.plot(freq, data_fft.imag, label='imaginary')\n",
        "plt.plot(freq, data_fft.real, label='real')\n",
        "plt.xlabel(\"Frequency (Hz)\")\n",
        "plt.ylabel(\"Power\")\n",
        "plt.ylim(-20, 20)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(16, 5))\n",
        "plt.title(\"FFT of template\")\n",
        "plt.plot(freq, template_fft.real, label='real')\n",
        "plt.plot(freq, template_fft.imag, label='imaginary')\n",
        "plt.xlabel(\"Frequency (Hz)\")\n",
        "plt.ylabel(\"Power\")\n",
        "plt.ylim(-20, 20)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(16, 5))\n",
        "plt.title(\"Real part of FFT of data and template\")\n",
        "plt.plot(freq, data_fft.real, label='data')\n",
        "plt.plot(freq, template_fft.real, label='template')\n",
        "plt.xlabel(\"Frequency (Hz)\")\n",
        "plt.ylabel(\"Power\")\n",
        "plt.ylim(-20, 20)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f02ed8e",
      "metadata": {
        "tags": [
          "learner",
          "md"
        ],
        "id": "1f02ed8e"
      },
      "source": [
        "Now, suppose we want to do the same thing we did in the time domain case: shift the template by a time $t$. What happens to the FFT? Consider the integral definition of a Fourier transform (as a substitute for the discrete case):\n",
        "\n",
        "$$\\mathcal{F}(\\omega) = \\int dt f(t)  e^{-2\\pi i\\omega t}$$\n",
        "\n",
        "So the FFT for a function shifted by $\\Delta t$ is\n",
        "\n",
        "$$\\int dt f(t - \\Delta t)  e^{-2\\pi i\\omega t} = \\int dt' f(t')  e^{-2\\pi i\\omega (t'+\\Delta t)} = e^{-2\\pi i \\omega \\Delta t}\\mathcal{F}(\\omega).$$\n",
        "\n",
        "The time-shifted FFT is just a constant multiplicative factor (albeit an imaginary number) times the initial template FFT!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62be737d",
      "metadata": {
        "tags": [
          "learner",
          "md"
        ],
        "id": "62be737d"
      },
      "source": [
        "So, suppose our data is indeed just our template, shifted by some time $\\Delta t$. We can find $\\Delta t$ from the data FFT $\\mathcal{D}$ and the template FFT $\\mathcal{T}$ using\n",
        "\n",
        "$$\\mathcal{D}(\\omega)=e^{-2\\pi i\\omega \\Delta t} \\mathcal{T}(\\omega) \\implies \\frac{\\mathcal{D}(\\omega)}{\\mathcal{T}(\\omega)}=e^{-2\\pi i\\omega \\Delta t} = \\frac{\\mathcal{D}(\\omega) \\mathcal{T}^*(\\omega)}{|\\mathcal{T}|^2(\\omega)}.$$\n",
        "\n",
        "The inverse Fourier transform (IFFT) of the constant exponential factor is a delta function at $\\Delta t$:\n",
        "\n",
        "$$f(t) = \\int d\\omega e^{-2\\pi i\\omega \\Delta t} e^{2\\pi i\\omega t} = \\delta(\\Delta t - t).$$\n",
        "\n",
        "Consequently, the peak of the IFFT of \n",
        "$$f(\\omega) =\\mathcal{D}(\\omega) \\mathcal{T}^*(\\omega)$$\n",
        "must also be centered at $\\Delta t$.\n",
        "\n",
        "There are some extra complications involved here, but the discussion above gives the gist of what happens. For more in-depth information, see the <a href=\"https://www.gw-openscience.org/s/events/GW150914/LOSC_Event_tutorial_GW150914.html\" target=\"_blank\">LIGO tutorial from which this code is inspired</a>."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4997fe33",
      "metadata": {
        "tags": [
          "learner",
          "md"
        ],
        "id": "4997fe33"
      },
      "source": [
        "Let's compute $f(\\omega)$ as given in the formula above. We call $f(\\omega)$ `optimal_fft`. Then, we take the IFFT and call it `optimal_time`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "901a0588",
      "metadata": {
        "tags": [
          "learner",
          "py",
          "learner_chopped"
        ],
        "id": "901a0588"
      },
      "outputs": [],
      "source": [
        "#>>>RUN: P2.5-runcell03\n",
        "\n",
        "fftout=np.fft.fft(yi_temp)\n",
        "optimal_fft = data_fft * template_fft.conjugate() / np.abs(fftout**2)\n",
        "plt.plot(freq,np.abs(optimal_fft))\n",
        "plt.title(\"optimal_fft\")\n",
        "plt.xlabel(\"Frequency (Hz)\")\n",
        "plt.ylabel(\"Power\")\n",
        "plt.show()\n",
        "\n",
        "#note the 2 is here b/c of the fft\n",
        "optimal_time = 2*np.fft.ifft(optimal_fft)*fs\n",
        "plt.plot(xi,optimal_time.real)\n",
        "plt.title(\"optimal_time\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Power\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a1353d7",
      "metadata": {
        "tags": [
          "learner",
          "md"
        ],
        "id": "4a1353d7"
      },
      "source": [
        "We should really plot some sort of signal to noise ratio, not `optimal_time` itself. Let's fix the ratio so that if the data is just noise, we have a ratio of one. We record the ratio as `SNR` and plot it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5697b083",
      "metadata": {
        "tags": [
          "learner",
          "py",
          "learner_chopped"
        ],
        "id": "5697b083"
      },
      "outputs": [],
      "source": [
        "#>>>RUN: P2.5-runcell04\n",
        "\n",
        "df = np.abs(freq[1] - freq[0])\n",
        "#compute the resolution sigma^2=(|S|^2/PSD)*Delta t\n",
        "sigmasq = 2*(template_fft * template_fft.conjugate() / fftout**2).sum() * df\n",
        "sigma = np.sqrt(np.abs(sigmasq))\n",
        "SNR = abs(optimal_time) / (sigma)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(xi, SNR)\n",
        "plt.xlabel('Offset time (s)')\n",
        "plt.ylabel('SNR');"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bf0ad62",
      "metadata": {
        "tags": [
          "learner",
          "md",
          "learner_chopped"
        ],
        "id": "5bf0ad62"
      },
      "source": [
        "<a name='section_7_2'></a>\n",
        "<hr style=\"height: 1px;\">\n",
        "\n",
        "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">P2.6 Analysis of Noisy Car Horn Data</h2>   \n",
        "\n",
        "| [Top](#section_6_0) | [Previous Section](#section_7_1) | [Problems](#problems_7_2) | [Next Section](#section_7_3) |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e94704bc",
      "metadata": {
        "tags": [
          "learner",
          "md"
        ],
        "id": "e94704bc"
      },
      "source": [
        "<h3>Setup for Problems</h3>\n",
        "\n",
        "In what follows, we will use a frequency based matched filtering algorithm to solve a different kind of problem. You will load two audio files: one containing a specific kind of car horn and another one containing street noise with this car horn sound inserted.\n",
        "\n",
        "Note that there are several car horn sounds embedded in the street noise sample but, if executed correctly, the frequency based matched filtering should be able to find the specific car horn sound we are looking for!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c368b57",
      "metadata": {
        "tags": [
          "py",
          "learner",
          "learner_chopped"
        ],
        "id": "1c368b57"
      },
      "outputs": [],
      "source": [
        "#>>>RUN: P2.6-runcell01\n",
        "\n",
        "import soundfile as sf\n",
        "import time\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "# Load the data into arrays\n",
        "yi_true, fs = sf.read('data/P06/street_noise.wav') \n",
        "yi_temp, fs = sf.read('data/P06/car_horn.wav')\n",
        "yi_true = yi_true[:,0]\n",
        "yi_temp = yi_temp[:,0]\n",
        "\n",
        "print(min,max)\n",
        "#play these guys\n",
        "min=int(22*(len(yi_true)/60))\n",
        "max=int(26*(len(yi_true)/60))\n",
        "\n",
        "def play(iArray,iFS):\n",
        "    sf.write('data/P06/tmp.flac', iArray, iFS)\n",
        "    display(Audio('data/P06/tmp.flac',autoplay=False))\n",
        "\n",
        "print(\"street_noise\")\n",
        "play(yi_true[min:max],fs)\n",
        "\n",
        "print(\"car horn\")\n",
        "play(yi_temp,fs)\n",
        "\n",
        "# Compresses the data to a smaller size by averaging 5 element chunks together\n",
        "# Note that this does not change the data, just decreases its resolution\n",
        "yi_true     = np.array(yi_true)\n",
        "yi_true_avg = np.average(yi_true.reshape(-1, 5), axis=1)\n",
        "\n",
        "\n",
        "\n",
        "# Make the template the same length as the signal by filling it with 0's\n",
        "# This is needed for the fft analysis to work\n",
        "yi_temp = np.concatenate((yi_temp, np.zeros(5*int(len(yi_temp)+1)-len(yi_temp))))\n",
        "yi_temp_avg = np.average(yi_temp.reshape(-1, 5), axis=1)\n",
        "yi_temp_avg = np.concatenate((yi_temp_avg, np.zeros(len(yi_true_avg)-len(yi_temp_avg))))\n",
        "\n",
        "\n",
        "# Create time array, from 0 to 60 second (the length of the street noise recording)\n",
        "# Time array also has the same resolution as the street noise, in order for fft analysis to work\n",
        "xi = np.linspace(0, 60, len(yi_true_avg))\n",
        "\n",
        "#Let's plot\n",
        "plt.plot(xi,yi_true_avg,label='merged sound')\n",
        "plt.plot(xi,yi_temp_avg,label='car horn')\n",
        "plt.xlabel('time(s)')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e648dc1",
      "metadata": {
        "tags": [
          "learner",
          "md",
          "learner_chopped"
        ],
        "id": "7e648dc1"
      },
      "source": [
        "<a name='problems_7_2'></a>   \n",
        "\n",
        "| [Top](#section_6_0) | [Restart Section](#section_7_2) | [Next Section](#section_7_3) |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c2e1f4f",
      "metadata": {
        "tags": [
          "learner",
          "md",
          "learner_chopped"
        ],
        "id": "8c2e1f4f"
      },
      "source": [
        "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 2.6.1</span>\n",
        "\n",
        "The code above loaded two datasets: one is a template containing the car horn and the other is true data containing car horn embedded into street noise. Using the same approach as in the previous section, first plot the real and imaginary parts of the FFT for both datasets. Also, plot the real parts of the FFT of the template compared to the noisy data. Fill in the missing code to accomplish this.\n",
        "\n",
        "Consider the plots of the template and the data in the frequency domain. Which sound sample has a greater range of frequencies (a spectrum with power more broadly and continuously spread over frequency)?\n",
        "\n",
        "A. Template\n",
        "\n",
        "B. Data\n",
        "\n",
        "C. They look very similar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dea76653",
      "metadata": {
        "tags": [
          "draft",
          "py",
          "learner_chopped"
        ],
        "id": "dea76653"
      },
      "outputs": [],
      "source": [
        "#>>>PROBLEM: P2.6.1\n",
        "# Use this cell for drafting your solution (if desired),\n",
        "# then enter your solution in the interactive problem online to be graded.\n",
        "\n",
        "\n",
        "#copy and paste the FFT\n",
        "fs = #YOUR CODE HERE\n",
        "data_fft = #YOUR CODE HERE\n",
        "template_fft = #YOUR CODE HERE\n",
        "freq = #YOUR CODE HERE\n",
        "\n",
        "\n",
        "plt.figure(figsize=(16, 5))\n",
        "plt.title(\"FFT of data\")\n",
        "plt.plot(freq, data_fft.real, label='real')\n",
        "plt.plot(freq, data_fft.imag, label='imaginary')\n",
        "plt.xlabel(\"Frequency (Hz)\")\n",
        "plt.ylabel(\"Power\")\n",
        "#plt.ylim(-20, 20)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(16, 5))\n",
        "plt.title(\"FFT of template\")\n",
        "plt.plot(freq, template_fft.real, label='real')\n",
        "plt.plot(freq, template_fft.imag, label='imaginary')\n",
        "plt.xlabel(\"Frequency (Hz)\")\n",
        "plt.ylabel(\"Power\")\n",
        "#plt.ylim(-20, 20)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(16, 5))\n",
        "plt.plot(freq,data_fft.real,label='data')\n",
        "plt.plot(freq,template_fft.real,label='signal')\n",
        "plt.xlabel('freq')\n",
        "plt.ylabel('N')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f687f0a",
      "metadata": {
        "tags": [
          "md",
          "learner",
          "learner_chopped"
        ],
        "id": "4f687f0a"
      },
      "source": [
        ">#### Follow-up 2.6.1a (ungraded)\n",
        ">   \n",
        ">Why does this answer make sense? Think about all the noise in the data that doesn't exist in the template.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2759049",
      "metadata": {
        "tags": [
          "learner",
          "md",
          "learner_chopped"
        ],
        "id": "d2759049"
      },
      "source": [
        "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 2.6.2</span>\n",
        "\n",
        "When looking at the FFT of the LIGO template shown earlier, there was a large difference between the real and imaginary parts of the frequency space. Is there a large difference in the real and imaginary parts of the car-horn template?\n",
        "\n",
        "\n",
        "A. Yes\n",
        "\n",
        "B. No\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "271dcf66",
      "metadata": {
        "tags": [
          "learner",
          "md",
          "learner_chopped"
        ],
        "id": "271dcf66"
      },
      "source": [
        "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 2.6.3</span>\n",
        "\n",
        "At what frequency (in Hz) does the power spectral density (PSD) spectrum of the data distribution peak? Enter your answer as a number with precision 1 (i.e. the closest integer).\n",
        "\n",
        "Hint: Take the absolute value of the FFT$^{2}$ of the data to get the PSD spectrum. Use the helpful command `np.argmax()` to find the index of the maximum element of the PSD. Use this index to find the frequency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92b00cd6",
      "metadata": {
        "tags": [
          "py",
          "draft",
          "learner_chopped"
        ],
        "id": "92b00cd6"
      },
      "outputs": [],
      "source": [
        "#>>>PROBLEM: P2.6.3\n",
        "\n",
        "freq_psd = #YOUR CODE HERE\n",
        "freq_psd_max = #YOUR CODE HERE\n",
        "\n",
        "plt.plot(freq,freq_psd,label='psd')\n",
        "plt.title(\"PSD of data\")\n",
        "plt.xlabel(\"Frequency (Hz)\")\n",
        "plt.ylabel(\"Power\")\n",
        "plt.show()\n",
        "print(\"Frequency at which the PSD is at its maximum: \", freq_psd_max)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af68c502",
      "metadata": {
        "tags": [
          "learner",
          "md",
          "learner_chopped"
        ],
        "id": "af68c502"
      },
      "source": [
        "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 2.6.4</span>\n",
        "\n",
        "At what time (in seconds) does the car horn signal modeled in the template occur in the data? Enter your answer as a number with precision 1e-1.\n",
        "\n",
        "Hint: Follow the example from what was done in Section P7.1 to find the time shift between the LIGO signal template and the data. Again, use `np.argmax()` to find the index of the maximum element of the `SNR`, and find the corresponding element of the time data array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e94f8fd7",
      "metadata": {
        "tags": [
          "py",
          "draft",
          "learner_chopped"
        ],
        "id": "e94f8fd7"
      },
      "outputs": [],
      "source": [
        "#>>>PROBLEM: P2.6.4\n",
        "\n",
        "\n",
        "optimal_fft = #YOUR CODE HERE\n",
        "optimal_time = #YOUR CODE HERE\n",
        "\n",
        "df = #YOUR CODE HERE\n",
        "sigmasq = #YOUR CODE HERE\n",
        "sigma =#YOUR CODE HERE\n",
        "SNR = #YOUR CODE HERE\n",
        "\n",
        "time_SNR_max = #YOUR CODE HERE\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(xi, SNR)\n",
        "plt.xlabel('Offset time (s)')\n",
        "plt.ylabel('SNR')\n",
        "plt.show()\n",
        "\n",
        "print(\"Time at which SNR peaks: \", time_SNR_max)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae39380a",
      "metadata": {
        "tags": [
          "md",
          "learner",
          "learner_chopped"
        ],
        "id": "ae39380a"
      },
      "source": [
        ">#### Follow-up 2.6.4a (ungraded)\n",
        ">   \n",
        ">The robustness of this approach is pretty impressive if you have a template that you are looking for in a sea of data. Listen to the audio files more closely. What are the other, smaller, peaks in the spectrum corresponding to? When do you hear other car horn noises in the data? Can you hear the template noise in the data at the correct time?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20a23596",
      "metadata": {
        "tags": [
          "md",
          "learner",
          "learner_chopped"
        ],
        "id": "20a23596"
      },
      "source": [
        ">#### Follow-up 2.6.4b (ungraded)\n",
        ">   \n",
        ">Change the data, perhaps by adding more noise or a different kind of noise, or by shifting the signal to a different time. What changes in the matched filter result?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "617bc7da",
      "metadata": {
        "tags": [
          "md",
          "learner",
          "learner_chopped"
        ],
        "id": "617bc7da"
      },
      "source": [
        ">#### Follow-up 2.6.4c (ungraded)\n",
        ">   \n",
        ">The runtime of the frequency domain matched filtering process was much faster than the time domain process. But we should not compare the two approaches directly because we tested against a template for the frequency version and performed a whole fit for the time version.\n",
        ">\n",
        ">If, instead of fitting, we used a fixed template for the time version as well, computing a $\\chi^2$ for every offset $t$ between the signal and the template and plotted $\\chi^2$ as a function of $t$, which method do you think would be faster now? Frequency or time?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08be6ff7",
      "metadata": {
        "tags": [
          "learner",
          "md",
          "learner_chopped"
        ],
        "id": "08be6ff7"
      },
      "source": [
        "<a name='section_7_3'></a>\n",
        "<hr style=\"height: 1px;\">\n",
        "\n",
        "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">P2.7 Calculating a Better Chi-square for the LIGO Model</h2>   \n",
        "\n",
        "| [Top](#section_7_0) | [Previous Section](#section_7_2) | [Problems](#problems_7_3) |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81a9b3f8",
      "metadata": {
        "tags": [
          "learner",
          "md"
        ],
        "id": "81a9b3f8"
      },
      "source": [
        "<h3>Overview</h3>\n",
        "\n",
        "Now, we are going to combine Fourier analysis and fitting of the time series information, to get a better notion of the $\\chi^{2}$. \n",
        "\n",
        "For this, we'll use similar data to what was used for fitting in the time domain, namely a merger signal embedded in 10 sine waves. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "379d6887",
      "metadata": {
        "scrolled": true,
        "tags": [
          "learner",
          "py",
          "learner_chopped"
        ],
        "id": "379d6887"
      },
      "outputs": [],
      "source": [
        "#>>>RUN: P2.7-runcell01\n",
        "\n",
        "np.random.seed(0x98a09fe)\n",
        "\n",
        "def complicated_model_fn(x, time, lambda_plus, lambda_minus, max_amp, omega_0, omega_max, omega_sigma):\n",
        "    omega = (omega_max - omega_0) * (np.exp(-np.minimum(x - time, 0)**2 / omega_sigma)) + omega_0\n",
        "    lambdas = np.array([lambda_plus if xvalue > time else lambda_minus for xvalue in x])\n",
        "    amplitude = max_amp * np.exp(-abs(x - time) / lambdas)\n",
        "    return amplitude * np.cos(omega * (x-time))\n",
        "\n",
        "\n",
        "params_min_max = {\n",
        "    'lambda_plus': (0.1, 5),\n",
        "    'lambda_minus': (0.1, 5),\n",
        "    'max_amp': (0, 2),\n",
        "    'omega_0': (0, 5),\n",
        "    'omega_max': (0, 10),\n",
        "    'omega_sigma': (0, 5),\n",
        "}\n",
        "\n",
        "def get_param_random_value(p_min,p_max):\n",
        "    #get a uniformly distributed random value between p_min and p_max\n",
        "    #return a float\n",
        "    return p_min + (p_max - p_min) * np.random.random(1)[0]\n",
        "\n",
        "def model_and_random_parameters(t):\n",
        "    model = Model(complicated_model_fn)\n",
        "    params = Parameters()\n",
        "    params.add('time', value=t, vary=False)\n",
        "    for p, (p_min, p_max) in params_min_max.items():\n",
        "        value = get_param_random_value(p_min,p_max)\n",
        "        params.add(p, min=p_min, max=p_max, value=value)\n",
        "    return model, params\n",
        "\n",
        "\n",
        "LAMBDA_PLUS_TRUE = 1.0\n",
        "LAMBDA_MINUS_TRUE = 4\n",
        "MAX_AMP_TRUE = 1.2\n",
        "OMEGA_0_TRUE = 3.0\n",
        "OMEGA_MAX_TRUE = 6.0\n",
        "OMEGA_SIGMA_TRUE = 4.0\n",
        "TIME_TRUE = 50.0\n",
        "\n",
        "xi = np.linspace(TIME_TRUE-15, TIME_TRUE+5, 200)\n",
        "true_yi = complicated_model_fn(xi, TIME_TRUE, LAMBDA_PLUS_TRUE, LAMBDA_MINUS_TRUE, MAX_AMP_TRUE,\n",
        "                               OMEGA_0_TRUE, OMEGA_MAX_TRUE, OMEGA_SIGMA_TRUE)\n",
        "\n",
        "NUMBER_SINES_TO_ADD = 10\n",
        "\n",
        "noise_frequencies = 0.5 + 7 * np.random.random(NUMBER_SINES_TO_ADD)\n",
        "noise_phases = 2 * np.pi * np.random.random(NUMBER_SINES_TO_ADD)\n",
        "noise_amplitudes = 2 * MAX_AMP_TRUE / NUMBER_SINES_TO_ADD * np.random.random(NUMBER_SINES_TO_ADD)\n",
        "    # The above line sets noise amplitudes so that the sum of all the noise amplitudes is on average\n",
        "    # equal to the maximum amplitude of the signal.\n",
        "\n",
        "plt.plot(xi, true_yi)\n",
        "plt.title(\"True Signal\")\n",
        "plt.xlabel(\"Time (s)\")\n",
        "plt.ylabel(\"Strain\")\n",
        "plt.show()\n",
        "\n",
        "sample_spacing = 0.1\n",
        "xi = np.arange(-128, 128, sample_spacing)#times\n",
        "yi = np.zeros_like(xi)#data\n",
        "\n",
        "#Adding Noise\n",
        "for freq, phase, amplitude in zip(noise_frequencies, noise_phases, noise_amplitudes):\n",
        "    yi += amplitude * np.sin(phase + freq * xi)\n",
        "\n",
        "#Adding Data\n",
        "signal= complicated_model_fn(xi, TIME_TRUE, LAMBDA_PLUS_TRUE, LAMBDA_MINUS_TRUE, MAX_AMP_TRUE,\n",
        "                               OMEGA_0_TRUE, OMEGA_MAX_TRUE, OMEGA_SIGMA_TRUE)\n",
        "yi+=signal\n",
        "\n",
        "plt.plot(xi, yi)\n",
        "plt.plot(xi, signal)\n",
        "plt.title(\"Signal plus noise\")\n",
        "plt.xlabel(\"Time (s)\")\n",
        "plt.ylabel(\"Strain\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(xi, yi)\n",
        "plt.plot(xi, signal)\n",
        "plt.title(\"Signal plus noise\")\n",
        "plt.xlim(35,55)\n",
        "plt.xlabel(\"Time (s)\")\n",
        "plt.ylabel(\"Strain\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3dc752ad",
      "metadata": {
        "tags": [
          "learner",
          "md"
        ],
        "id": "3dc752ad"
      },
      "source": [
        "<h3>Plotting the Fit from Before (time-domain)</h3>\n",
        "\n",
        "Here we plot the fit, defining a slightly different function that will also return the data arrays. Run it multiple times to find the minimum $\\chi^2$ value and corresponding maximum $\\chi^2$ probability.\n",
        "\n",
        "**Note:** Since we will use this fit going forward, be sure to run it until the best fit (minimum $\\chi^2$) is found and **make sure** that a fit resulting in this lowest value is the **last fit** that you run. To ensure that you end on the correct fit, it's best **not** to use a `for` loop in this case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ea18a0c",
      "metadata": {
        "scrolled": true,
        "tags": [
          "learner",
          "py",
          "learner_chopped"
        ],
        "id": "7ea18a0c"
      },
      "outputs": [],
      "source": [
        "#>>>RUN: P2.7-runcell02\n",
        "\n",
        "#Getting the fit (defining a slightly different function than previously)\n",
        "\n",
        "import lmfit\n",
        "\n",
        "\n",
        "def get_signal_indices(xi, t, t_before, t_after):\n",
        "    #use np.where() to return a 1D the relevant indices\n",
        "    #note, the result of np.where() will be a tuple\n",
        "    return np.where((xi > t - t_before) & (xi < t + t_after))\n",
        "\n",
        "def fit_once_apply(t, t_before, t_after, weight=1.0):\n",
        "    data_indices = get_signal_indices(xi, t, t_before, t_after)\n",
        "    data_x = xi[data_indices]\n",
        "    data_y = yi[data_indices]\n",
        "    weights = np.ones(len(data_x))*weight\n",
        "    model, params = model_and_random_parameters(t)\n",
        "    result = model.fit(data_y, params, x=data_x,weights=weights)\n",
        "    fitted_y = model.eval(x=data_x,params=result.params)\n",
        "    result.plot()\n",
        "    print(\"Fit chi2 value: \", result.chisqr)\n",
        "    print(\"Fit chi2 probability: \",1-stats.chi2.cdf(result.chisqr,result.nfree))\n",
        "    return data_x,data_y,fitted_y\n",
        "\n",
        "t_before = 5\n",
        "t_after = 2\n",
        "unc=0.2\n",
        "fit_x,d_y, fit_y = fit_once_apply(TIME_TRUE, t_before, t_after, 1./unc)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11fca707",
      "metadata": {
        "tags": [
          "learner",
          "md"
        ],
        "id": "11fca707"
      },
      "source": [
        "Now, your job is to compute a more meaningful $\\chi^{2}$ value by taking the above data and fitted prediction and transforming them into Fourier space and plotting them together."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3241ee37",
      "metadata": {
        "tags": [
          "learner",
          "md",
          "learner_chopped"
        ],
        "id": "3241ee37"
      },
      "source": [
        "<a name='problems_7_3'></a>   \n",
        "\n",
        "| [Top](#section_6_0) | [Restart Section](#section_7_3) |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "297f3e69",
      "metadata": {
        "tags": [
          "learner",
          "md",
          "learner_chopped"
        ],
        "id": "297f3e69"
      },
      "source": [
        "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 2.7.1</span>\n",
        "\n",
        "As a first step, take the data and the fitted function in the time range they were fitted, and plot them in Fourier space. At approximately what frequency value (in Hz) does the amplitude decay to negligible levels? Enter your answer as a number with precision $\\pm 0.01$ Hz.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41cf24e5",
      "metadata": {
        "tags": [
          "py",
          "draft",
          "learner_chopped"
        ],
        "id": "41cf24e5"
      },
      "outputs": [],
      "source": [
        "#>>>PROBLEM: P2.7.1\n",
        "\n",
        "fftdata = #YOUR CODE HERE\n",
        "fftfit  = #YOUR CODE HERE\n",
        "\n",
        "freq = np.fft.fftfreq(fit_x.shape[0])*sample_spacing\n",
        "\n",
        "freq    = freq   [0:freq.shape[0]//2]\n",
        "fftfit  = fftfit [0:fftfit.shape[0]//2]\n",
        "fftdata = fftdata[0:fftdata.shape[0]//2]\n",
        "\n",
        "#print(fftdata.shape,fftfit.shape)\n",
        "plt.plot(freq,fftdata.real,label='data')\n",
        "plt.plot(freq,fftfit.real,label='fit')\n",
        "plt.xlabel('freq')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d16c205",
      "metadata": {
        "tags": [
          "learner",
          "md",
          "learner_chopped"
        ],
        "id": "5d16c205"
      },
      "source": [
        "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 2.7.2 </span>\n",
        "\n",
        "Now, we want to compute the noise as a function of frequency. We can do this by taking a region where there is no signal and computing the standard deviation of our samples in Fourier space. Notice that the code does this in each of the same frequency bins that were used to compute the FFT, and uses `np.stddev(axis=0)` to compute the standard deviation of a 2D array.\n",
        "\n",
        "Run the code below. What does this noise spectrum look like? Choose from the following options:\n",
        "\n",
        "- A uniform distribution across all frequencies.\n",
        "- A decaying exponential function, peaked at low frequencies.\n",
        "- An increasing exponential function, peaked at high frequencies.\n",
        "- A function with multiple peaks in the low frequency range, decreasing in the high frequency range.\n",
        "- A function with multiple peaks in the high frequency range, decreasing in the low frequency range.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "479a54e0",
      "metadata": {
        "scrolled": true,
        "tags": [
          "py",
          "draft",
          "learner_chopped"
        ],
        "id": "479a54e0"
      },
      "outputs": [],
      "source": [
        "#>>>PROBLEM: P2.7.2\n",
        "\n",
        "def fft_region(t, t_before, t_after):\n",
        "    data_indices = get_signal_indices(xi, t, t_before, t_after)\n",
        "    data_x = xi[data_indices]\n",
        "    data_y = yi[data_indices]\n",
        "    fft_sample = np.fft.fft(data_y)\n",
        "    fft_sample=fft_sample[0:fft_sample.shape[0]//2]\n",
        "    return fft_sample\n",
        "\n",
        "tsample=np.arange(-128, 128,10)\n",
        "\n",
        "t_before = 5\n",
        "t_after = 2\n",
        "\n",
        "ffts=np.array([])\n",
        "for t in tsample:\n",
        "    if abs(t-TIME_TRUE) > 10:\n",
        "        pfft=fft_region(t, t_before, t_after)\n",
        "        if pfft.shape[0] == 35:\n",
        "            ffts = np.append(ffts,pfft)\n",
        "            \n",
        "ffts   = np.reshape(ffts,(len(ffts)//35,35))\n",
        "stddev = ffts.std(axis=0)\n",
        "plt.plot(freq,stddev)\n",
        "plt.xlabel('freq')\n",
        "plt.ylabel('std deviation')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7090ec68",
      "metadata": {
        "tags": [
          "learner",
          "md",
          "learner_chopped"
        ],
        "id": "7090ec68"
      },
      "source": [
        "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 2.7.3 </span>\n",
        "\n",
        "Finally, make a plot of the Fourier transforms of the data and the best time-domain fit, similar to what was done at the beginning of this section, but now in frequency space. Include error bars on each data point equal to the standard deviation of the corresponding frequency found in P7.3.1 above.\n",
        "\n",
        "What is the $\\chi^{2}$ value between the data and the fit (i.e. $\\sum (\\textrm{data}-\\textrm{fit})^2/\\textrm{unc}^2$) and its associated probability? Note that the number of degrees of freedom is the number of bins minus the number of fit parameters, the latter being 7 in this case.\n",
        "\n",
        "Enter your answer as a list of numbers `[chi2, chi2_prob]` with precision 1e-1.  \n",
        "\n",
        "**NOTE: make sure you perform this analysis with respect to the time-domain fit that yielded the lowest $\\chi^2$ value.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7084570",
      "metadata": {
        "tags": [
          "md",
          "learner",
          "learner_chopped"
        ],
        "id": "b7084570"
      },
      "source": [
        ">#### Follow-up 2.7.3a (ungraded)\n",
        ">   \n",
        ">Why is the fit probability found using this frequency-domain technique more meaningful than the p-value obtained from the time-domain fit itself?"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Tags",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}